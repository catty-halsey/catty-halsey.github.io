---
layout: post
title: "Hypothesis test"
author: "Ziyan Li"
categories: journal
tags: [documentation, sample]
---

The hypothesis test allows us to test whether our sample (collected data) has certain properties. For example, we are interested in the mean, variance and other parameter of interest of one sample or two samples. In practice, we construct our test statistic to approximate the parameter of our interests. Now, the hypothesis test is provide us a tool to test whether our test statistic measure closely to our true parameter of interest or deviate from it. And if it close to the true parameter of interest, in what probability we can believe our results.

To construct a hypothesis, we first decide the null hypothesis $H_0$ against the alternative hypothesis $H_1$. Then, we need to design the test for null hypothesis.  There are two types of test, namely, the randomized test and non-randomized test. The randomized test maps $\mathscr{X}$ to the interval $[0,1]$ and the non-randomized test maps $\mathscr{X}$ to $\\{0,1\\}$. We define the significant level $\alpha$ as $\sup_{\theta \in \Theta_0} E_{\theta}[\phi(X)] \leq \alpha$. In hypothesis testing, we aim to evaluate a null hypothesis $H_0$ against an alternative hypothesis $H_1$ while controlling the probability of incorrectly rejecting $H_0$, known as the Type I error rate $\alpha$. To achieve this, we design our test function $\phi(X)$ to map observed data $X$ to $[0, 1]$, where $\phi(X) = 1$ indicates rejection of $H_0$. When the observed data is extreme or inconsistent with $H_0$, we want to classify it in the rejection region, thereby mapping these extreme values to $1$. This approach helps us control the proportion of extreme observations leading to rejection, ensuring that $E_{H_0}[\phi(X)] \leq \alpha$. This principle applies to both randomized and non-randomized tests, where the objective is to keep the likelihood of false rejections within our chosen significance level. 

Let we clarify some motivation of randomized test: In hypothesis testing, there are situations where the evidence is inconclusiveâ€”neither strongly supporting the null hypothesis $H_0$ nor providing enough evidence to reject it in favor of the alternative $H_1$. In these cases, we may use a randomized test to make a probabilistic decision. Specifically, when our test statistic produces a value that falls in this ambiguous region, we assign a probability $p$ of rejecting $H_0$. This is done through a random mechanism, such as flipping a biased coin with success probability $p$, where "success" means rejecting $H_0$. By designing $p$ to meet the condition:

$$
\mathbb{E}_{\theta \in \Theta_0}[\phi(X)] \leq \alpha,
$$

We ensure that, on average, the test's false rejection rate stays within the significance level $\alpha$ under $H_0$. This approach lets us manage "borderline" cases with a controlled chance of rejection, while still maintaining the statistical rigor of the test. After we design the test, 

The Neyman-Pearson lemma provides a way to design the most powerful test for distinguishing between two simple hypotheses H_0$ and H_1$. Suppose we have:

- Null hypothesis: $H_0: \theta = \theta_0$
- Alternative hypothesis: $H_1: \theta = \theta_1 > \theta_0$

The likelihood ratio test statistic $\Lambda(X)$ is defined as:

$$
\Lambda(X) = \frac{L(X | \theta_1)}{L(X | \theta_0)}
$$

where $L(X | \theta)$ is the likelihood of observing $X$ given parameter $\theta$.

The Neyman-Pearson lemma states that the most powerful test for a given significance level $\alpha$ has the form:

$$
\phi(X) = 
\begin{cases} 
1 & \text{if } \Lambda(X) \geq k \\
0 & \text{if } \Lambda(X) < k
\end{cases}
$$

where $k$ is chosen such that the test has size $\alpha$, meaning:

$$
E_{\theta_0}[\phi(X)] = P_{\theta_0}(\Lambda(X) \geq k) = \alpha
$$

In cases where $\Lambda(X) = k$ falls within a critical boundary, the test may be randomized by setting:

$$
\phi(X) = 
\begin{cases} 
1 & \text{if } \Lambda(X) > k \\
p & \text{if } \Lambda(X) = k \\
0 & \text{if } \Lambda(X) < k
\end{cases}
$$

where $p$ is chosen to satisfy the exact level $\alpha$. This approach ensures that the test maximizes the probability of correctly rejecting $H_0$ when $H_1$ is true while controlling the probability of a Type I error at $\alpha$.

ALternatively, when we want to test 

- Null hypothesis: $H_0: \theta = \theta_0$
- Alternative hypothesis: $H_1: \theta = \theta_1 < \theta_0$

The likelihood ratio test statistic $\Lambda(X)$ is defined as:

$$
\Lambda(X) = \frac{L(X | \theta_1)}{L(X | \theta_0)}
$$

where $L(X | \theta)$ is the likelihood of observing $X$ given parameter $\theta$.

The Neyman-Pearson lemma states that the most powerful test for a given significance level $\alpha$ has the form:

$$
\phi(X) = 
\begin{cases} 
1 & \text{if } \Lambda(X) \leq k \\
0 & \text{if } \Lambda(X) > k
\end{cases}
$$

where $k$ is chosen such that the test has size $\alpha$, meaning:

$$
E_{\theta_0}[\phi(X)] = P_{\theta_0}(\Lambda(X) \leq k) = \alpha
$$

In cases where $\Lambda(X) = k$ falls within a critical boundary, the test may be randomized by setting:

$$
\phi(X) = 
\begin{cases} 
1 & \text{if } \Lambda(X) > k \\
p & \text{if } \Lambda(X) = k \\
0 & \text{if } \Lambda(X) < k
\end{cases}
$$

TWO REMARKS:
- Note that although the test statistic remains as the likelihood ratio, the desgin test changes. Hence, how we formulate our null hypothesis matters a lot. Additionally, in general, we require to find the distribution of the test statistic (the likelihood ratio in NP-test) and use $E_{\theta_0}[\phi(X)] = P_{\theta_0}(\Lambda(X) \geq k) = \alpha$ to find our threshold $k$ for the test statistics. 
- For both NP-tests above, they are one-sided tests. By Neymann-Pearson lemma, NP-test is the uniformly most powerful test with level $\alpha$. Mathematically, it holds that $E_{\theta_1}[\phi(X)] \leq E_{\theta_1}[\phi_{NP}(X)]$ and $E_{\theta_0}[\phi(X)]=\alpha$. However, when we want to implement the two-sided test, this lemma implies the uniqueness of the NP-test. By the above construction, we notice that this is impossible in general. Hence, the NP-tests does not exists sometimes. This will lead us to a new topic how to construct a test for all hypothesis test and have the similar properties as NP-test (such largest power at level $\alpha$).

Before we move into the new topic, we show two examples of NP-test




