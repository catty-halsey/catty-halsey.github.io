---
lawet: post
title: "The Metropolis-Hastings"
author: "Ziyan Li"
categories: journal
tags: [documentation, sample]
---


The Metropolis-Hastings algorithm is a cornerstone method in Markov Chain Monte Carlo (MCMC) for sampling from a target distribution $\pi$, even when direct sampling is infeasible. The brilliance of the algorithm lies in its design of the acceptance ratio $a(x, y)$, which, combined with the proposal distribution $Q(x, y)$, ensures that the Markov chain converges to the desired stationary distribution. The acceptance ratio is defined as $a(x, y) = \min\left(1, \frac{\pi(y) Q(y, x)}{\pi(x) Q(x, y)}\right)$, and its role is to correct for discrepancies between the proposal $Q$ and the target $\pi$. By carefully filtering proposed transitions, $a(x, y)$ ensures that only those candidate states $y$ which maintain the balance equation $\pi(x) P(x, dy) = \pi(y) P(dy, x)$ are accepted, where $P(x, dy)$ is the transition kernel that combines $Q(x, y)$ with $a(x, y)$. This clever design means that the accepted states automatically satisfy the balance equation, guaranteeing that the chain converges to $\pi$ over time.

Intuitively, if the ratio $\frac{\pi(y) Q(y, x)}{\pi(x) Q(x, y)}$ exceeds 1, meaning the proposed state $y$ is more likely under $\pi$ than the current state $x$, then $y$ is always accepted. Conversely, if the ratio is less than or equal to 1, $y$ is accepted with a probability proportional to the ratio, which prevents bias and ensures the chain properly explores $\pi$. This automatic adjustment is the key insight of the algorithm, transforming any mismatched proposal $Q$ into a valid kernel $P$ that respects the target distribution. Consequently, the $a(x, y)$ design not only ensures convergence to $\pi$ but also facilitates efficient exploration of the state space.



